{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenuti\n",
    "\n",
    "- [Esercitazione MLP](#Esercitazione-MLP)\n",
    "- [Import](#Import)\n",
    "- [Dataset](#Dataset)\n",
    "    - [Le feature utilizzate](#Le-feature-utilizzate)\n",
    "    - [Caricamento](#Caricamento)\n",
    "    - [Creazione di train e validation set](#Creazione-di-train-e-validation-set)\n",
    "- [Import di TensorFlow 2.x](#Import-di-TensorFlow-2.x)\n",
    "- [Definizione del modello](#Definizione-del-modello)\n",
    "- [Addestramento](#Addestramento)\n",
    "- [Esercizio](#Esercizio)\n",
    "- [Test](#Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione MLP\n",
    "Nell'esercitazione odierna si applicherà una rete *Multilayer Perceptron* (MLP) a un problema di classificazione di tracce audio in cui viene pronunciata una singola cifra (da 0 a 9, in italiano). L'obiettivo è quello di classificare la traccia audio in modo da predire:\n",
    "- A) la cifra che viene pronunciata (digit recognition). \n",
    "- B) la persona che l'ha pronunciata (speaker recognition).\n",
    "\n",
    "Sul problema A lavoreremo insieme durante la lezione. Il problema B sarà oggetto della competizione (CodaLab).\n",
    "\n",
    "Per questa esercitazione si farà uso del framework **TensorFlow** (versione 2.x) e di alcune funzionalità messe a disposizione dalla libreria Scikit-learn.\n",
    "\n",
    "Nel corso dell'esercitazione si dovrà definire l'architettura di una rete neurale in grado di risolvere il problema di classificazione e ottimizzare il suo training (in modo da massimizzare l’accuratezza sul dataset fornito).\n",
    "Infine si dovrà misurare l'accuratezza ottenuta (utilizzando la soluzione trovata in precedenza) sul dataset di test (scaricabile dal sito del corso) per verificarne l’effettiva capacità di generalizzazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "Per prima cosa è necessario eseguire l'import delle librerie utilizzate durante l'esecitazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import time\n",
    "import IPython\n",
    "from ml_visualization import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Il dataset è composto dalle tracce audio raccolte da 31 persone (grazie a tutti coloro che hanno contribuito!). Ciscuna persona ha registrato 10 tracce ripetendo i dieci digit in 4 sessioni diverse:\n",
    "- 1 - Ambiente silenzioso (condizioni ottimali)\n",
    "- 2 - Ambiente silenzioso (mattina poco dopo risveglio)\n",
    "- 3 - Ambiente rumoroso (ad esempio all'esterno con traffico)\n",
    "- 4 - Con rumore di fondo tipo TV o radio\n",
    "\n",
    "Il training set contiene le tracce delle sessioni 1 e 4, per un totale di 620 pattern (2 x 31 x 10). Il test set contiene le tracce delle sessioni 2 e 3, per un totale di 620 pattern (2 x 31 x 10). Il dataset è fornito sotto forma di blob NumPy.\n",
    "\n",
    "Non utilizzeremo i file audio grezzi perchè le reti MLP non sono in grado di gestire efficacemente dati multidimensionali di tale complessità. Pertanto sono state pre-estratte feature \"compatte\" come descritto nella cella seguente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le feature utilizzate\n",
    "\n",
    "Il dataset consiste in un insieme di feature estratte dalle tracce audio. In particolare sono rese disponibili le MFCC, Chroma, Mean of Mel spectrogram, Spectral Contrast e Tonnetz.\n",
    "\n",
    "Tra le feature più utilizzate per il riconoscimento del parlato troviamo le **MFCC (Mel Frequency Cepstral Coefficients)**. Si tratta di una rappresentazione particolarmente adatta per il riconoscimento vocale in quanto condensa le informazioni della traccia originale cercando di estrarre le informazioni utilizzate dal sistema uditivo umano. Hanno il grande pregio di essere feature molto compatte e per questo particolarmente indicate per poter essere processate dai comuni algoritmi di Machine Learning.\n",
    "\n",
    "Per poter comprendere il contenuto delle MFCC è necessario prima di tutto comprendere come lo Spettrogramma di Mel viene calcolato ([qui una spiegazione semplificata](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53)). \n",
    "\n",
    "![title](MelSpectrogram.png)\n",
    "\n",
    "A partire dallo Spettrogramma di Mel è molto semplice ottenere le *MFCC* attraverso un'ulteriore trasformata coseno che decorrela i coefficienti dello spettrogramma ([spiegazione semplificata](https://medium.com/@tanveer9812/mfccs-made-easy-7ef383006040)).\n",
    "\n",
    "\n",
    "Oltre alle MFCC sono anche disponibili altre feature che potrebbero rivelarsi utili ai fini della classificazione delle tracce audio. Ogni pattern del dataset è un vettore composto da 173 feature *floating point*. Il vettore è così suddiviso:\n",
    "\n",
    "- Features [0:20): MFCC\n",
    "- Features [20:32): Chroma (https://en.wikipedia.org/wiki/Chroma_feature)\n",
    "- Features [32:160): Media dello Spettrogramma di Mel\n",
    "- Features [160:167): Spectral Contrast ([paper](http://hcsi.cs.tsinghua.edu.cn/Paper/Paper02/200218.pdf))\n",
    "- Features [167:173): Tonnetz ([paper](http://rose.ofai.at/~martin.gasser/papers/oefai-tr-2006-13.pdf))\n",
    "\n",
    "Ai fini dell'esercitazione non è richiesta la conoscenza teorica della composizione delle feature in questione. Tuttavia si consideri la possibilità di usarne solo alcune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento\n",
    "Il training set viene fornito sotto forma di un unico file \"audio_ml2122_train.npy\" contenente sia le feature che le etichette di classe delle tracce audio. La procedura per il caricamento del dataset è fornita nella cella seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "train_dataset = np.load('DBs/AudioDigits_ML21_22/audio_ml2122_train.npy')\n",
    "print('Shape del dataset:', train_dataset.shape)\n",
    "\n",
    "# Posizione delle etichette (per il problema A si usa digit_column, per il problema B speaker_column)\n",
    "digit_column = 173\n",
    "speaker_column = 174\n",
    "\n",
    "# Le ultime due colonne sono lasciate alle etichette (digit e speaker)\n",
    "dataset_x = train_dataset[:, :-2].astype(np.float32)\n",
    "dataset_y = train_dataset[:, digit_column].astype(int)   \n",
    "print('Shape del training set (X):', dataset_x.shape)\n",
    "print('Shape del training set (Y):', dataset_y.shape)\n",
    "\n",
    "# Etichette di classe\n",
    "digit = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "print('Numero di pattern per ogni classe:')\n",
    "class_labels, count = np.unique(dataset_y, return_counts=True)\n",
    "for label, n_patterns in zip(class_labels, count):\n",
    "    print(digit[label], '->', n_patterns, 'patterns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il test set viene fornito in due file separati: \"audio_ml2122_test_no_labels.npy\" (comune ai problemi A e B) e \"audio_ml2122_test_digit_labels.npy\" contenente le etichette per il problema A. Ovviamente le etichette per il problema B non sono date.\n",
    "\n",
    "La procedura per il caricamento del test set è fornita nella cella seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset (test)\n",
    "test_x = np.load('DBs/AudioDigits_ML21_22/audio_ml2122_test_no_labels.npy')\n",
    "test_y = np.load('DBs/AudioDigits_ML21_22/audio_ml2122_test_digit_labels.npy')\n",
    "print('Shape del dataset X:', test_x.shape)\n",
    "print('Shape del dataset Y:', test_y.shape)\n",
    "\n",
    "# Conversione dei dati (test)\n",
    "test_x = test_x.astype(np.float32)\n",
    "test_y = test_y.astype(int)\n",
    "print('Shape del test set (X):', dataset_x.shape)\n",
    "print('Shape del test set (Y):', dataset_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione di train e validation set\n",
    "Il successivo passo consiste nell'ottenere un training set e un validation set. A tal fine viene utilizzata la funzione [**train_test_split(...)**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) messa a disposizione da Scikit-learn.\n",
    "\n",
    "È possibile scegliere la percentuale di pattern da utilizzare nel validation set modificando il parametro *validation\\_size*.\n",
    "\n",
    "La cella seguente esegue anche una normalizzazione dei dati utilizzando [**StandardScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) fornito da Scikit-learn. Questa normalizzazione si rivela essere particolarmente utile quando si intende utilizzare delle reti neurali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split del dataset in training e validation\n",
    "validation_size = 0.2\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(dataset_x, dataset_y, test_size=validation_size, random_state = 1234)\n",
    "\n",
    "print('Training dataset contains', len(train_x), 'patterns')\n",
    "print('Validation dataset contains', len(valid_x), 'patterns')\n",
    "\n",
    "print('Training dataset shape', train_x.shape, train_y.shape)\n",
    "print('Validation dataset shape', valid_x.shape, valid_y.shape)\n",
    "\n",
    "# Applica nomralizzazione con StandardScaler di scikit-learn\n",
    "scaler = StandardScaler().fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "valid_x = scaler.transform(valid_x)\n",
    "\n",
    "# Applica normalizzazione anche al test\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import di TensorFlow 2.x\n",
    "\n",
    "Il prossimo passo è quello di caricare il framework TensorFlow. Per questa esercitazione verrà utilizzata la versione più recente (2.x).\n",
    "\n",
    "Nel momento stesso in cui viene eseguito l'import, TensorFlow controlla se nel PC è presente un dispositivo (come una GPU dedicata) in grado di velocizzare i calcoli solitamente impiegati per l'addestramento e uso di reti neurali. Oltre ad eseguire l'import di Tensor Flow la prossima cella mostrerà anche i dispositivi rilevati. Se non è presente alcun acceleratore verrà mostrata solamente la CPU.\n",
    "\n",
    "Si noti come TensorFlow, se non configurato diversamente, utilizzerà automaticamente tutti gli acceleratori presenti nel sistema. In questo caso, per evitare di appesantire sistemi dotati di più GPU, utilizziamo la variabile di ambiente *CUDA\\_VISIBLE\\_DEVICES* per rendere utilizzabile solo la prima GPU. Se si imposta *CUDA\\_VISIBLE\\_DEVICES = -1*, anche in presenza di GPU, si forza TensorFlow a usare la sola CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Nasconde messaggi di debug\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Rende visibile solo la GPU 0\n",
    "\n",
    "# Import TensorFlow 2.x\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from tensorflow.python.client import device_lib\n",
    "print('Tensorflow Version', tf.__version__)\n",
    "\n",
    "# Mostra i dispositivi disponibili\n",
    "\n",
    "print (\"\\nHardware Devices:\")\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definizione del modello\n",
    "\n",
    "Una volta eseguito l'import di TensorFlow è possibile procedere a definire il modello (l'architettura della rete) che si intende utilizzare. Il modo più semplice è quello di utilizzare l'API **Keras** che permette di definire una rete neurale semplicemente descrivendo la struttura e l'ordine degli strati di cui è composta.\n",
    "\n",
    "In particolare per questa esercitazione verranno utilizzati solamente *layer* di tipo *fully connected*. In Keras questi layer sono implementati nella classe [**Dense**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).\n",
    "\n",
    "I principali parametri sono rappresentati:\n",
    "\n",
    "1. Dal numero di valori di output, impostato dal primo parametro. Si noti come l'ultimo layer deve obbligatoriamente avere un numero di output pari al numero di classi del problema da risolvere (in questo caso 10).\n",
    "2. Dalla funzione di attivazione. Sono disponibili diverse funzioni (si veda la documentazione). La funzione di attivazione per l'ultimo layer dovrà sempre essere *softmax*.\n",
    "\n",
    "La classe **Sequential** ([tutorial](https://www.tensorflow.org/guide/keras/sequential_model)) permette di gestire automaticamente il collegamento tra i successivi layer della rete permettendo allo sviluppatore di non dover specificare la *shape* delle attivazioni intermedie.\n",
    "\n",
    "Nota: Keras è anche disponibile come API di alto livello installabile in maniera *indipendente dal framework* e in grado di sfruttare motori di esecuzione diversi da TensorFlow (ad esempio *MXNet* di Amazon). Google tuttavia ha ben integrato Keras in TF 2.x, per cui si consiglia sempre di riferirsi alla documentazione di *tf.keras* disponibile [qui](https://www.tensorflow.org/api_docs/python/tf/keras/) e non a quella presente sul sito *keras.io*.\n",
    "\n",
    "Di seguito è definita la funzione che verrà richiamata per costruire il modello. Questo, una volta creato tramite *Sequential*, viene \"compilato\". La funzione *compile(...)* lega il modello all'ottimizzatore e alla funzione di *loss* da utilizzare per l'addestramento. A queste si aggiungono eventuali metriche da utilizzare per verificare la bontà del modello (in questo caso, essendo un problema di classificazione, l'accuratezza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedura di creazione del modello\n",
    "def build_model(n_features):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='tanh', input_shape=[n_features]),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(0.005)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento\n",
    "\n",
    "La seguente cella mostra il codice richiesto per istanziare e addestrare il modello. Il modello parte da pesi scelti casualmente dal framework. Il metodo [**.summary(...)**](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary) permette di visualizzare al struttura della rete, compreso il numero dei parametri addestrabili.\n",
    "\n",
    "Verificare che il numero di parametri addestrabili sia quello atteso dato il numero di livelli e neuroni (tipica domanda all'esame).\n",
    "\n",
    "In questo esempio viene anche mostrato come utilizzare la tecnica di *early stopping*, implementata in TensorFlow nella classe [**EarlyStopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping). Questa permette di terminare prematuramente l'addestramento se la variabile monitorata (*val\\_loss*, ovvero la loss sul validation set) non diminuisce per il numero specificato di iterazioni.\n",
    "\n",
    "Si noti come il metodo **.fit(...)** sia molto simile a quello visto nell'API offerta da Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(train_x.shape[1])\n",
    "model.summary()\n",
    "\n",
    "n_epochs = 50\n",
    "minibatch_size = 32\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y),\n",
    "                    epochs=n_epochs, batch_size=minibatch_size, shuffle=True,\n",
    "                    verbose=0, callbacks=[early_stop, tfdocs.modeling.EpochDots(report_every=10, dot_every=1)])\n",
    "\n",
    "print('\\nTraining MLP completato in %.2f s.' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione *.fit(...)* restituisce l'andamento del valore numerico di diverse metriche classiche. Analizzare visivamente questi valori può essere utile per individuare eventuali anomalie e per correggere sia la struttura del modello che gli iperparametri dell'ottimizzatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=0)\n",
    "\n",
    "plotter.plot({'Basic': history}, metric=\"accuracy\")\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plotter.plot({'Basic': history}, metric=\"loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, **una volta ottenuta una configurazione ritenuta ottimale**, sarà possibile verificare la soluzione anche sul test set. Nella cella seguente verrà visualizzata l'accuratezza e la Confusion Matrix del modello sul test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_x)\n",
    "test_predictions = test_predictions.argmax(axis=-1)\n",
    "\n",
    "print('Accuratezza sul test set:', accuracy_score(test_y, test_predictions) * 100, '%')\n",
    "\n",
    "plot_confusion_matrix(test_y, test_predictions, classes=['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio\n",
    "\n",
    "L'obiettivo è quello di massimizzare l'accuratezza di classificazione per il **problema di riconoscimento dello speaker** (problema B, 31 classi), di cui non sono date le etichette. Il dataset di test è lo stesso usato per il problema di riconoscimento delle cifre. \n",
    "\n",
    "- Si consideri la possibilità di **modificare l'architettura della rete** aggiungendo o rimuovendo layer e modificando il numero di neuroni per ogni livello;\n",
    "- **Modificare la funzione di attivazione** può potenzialmente migliorare il modello. Si noti come, a seconda della funzione utilizzata, potrebbe essere necessario adattare il modo con cui sono generati i pesi casuali iniziali. La generazione casuale dei pesi è controllata tramite il parametro *kernel\\_initializer* dei layer *Dense*;\n",
    "- È possibile **modificare l'ottimizzatore** (e i relativi iperparametri) utilizzando uno di quelli disponibili in Keras ([qui la lista completa](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers));\n",
    "- Applicare una **regolarizzazione L1 o L2** può prevenire alcuni problemi di under o overfitting e di convergenza. A tal fine si consideri l'uso del parametro *kernel\\_regularizer* dei layer *Dense*;\n",
    "- È possibile utilizzare **uno *scheduler* del Learning Rate** tra quelli disponilibi in Keras ([qui la lista completa](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)). Nella documentazione dei vari scheduler sono presenti semplici esempi che mostrano come utilizzarli.\n",
    "- Si consiglia di definire un codice con cui **eseguire una Cross Validation efficace**. Nel libro di A. Geron, \"Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent System\" è spiegato come \"wrappare\" modelli di Keras in modo da rendere possibile l'uso della funzionalità di CrossValidation e GridSearch di Scikit-learn;\n",
    "- Ricordate che una volta definiti gli iperparametri e la procedura ottimale di training può convenire utilizzare tutto il training set per l'addestramento finale (senza escludere porzione di validation).\n",
    "\n",
    "Ai fini dell'esercizio valgono le seguenti regole:\n",
    "\n",
    "- Non è possibile aggiungere al training set dati esterni, inclusi i dati del test set;\n",
    "- Non si possono utilizzare le etichette (del problema A) per la risoluzione del problema B.\n",
    "- Sì può eseguire una data augmentation inserendo feature derivate (anche se non è semplice visto il formato di input). Può essere utilizzato un sottoinsieme delle feature.\n",
    "- Nel modello potranno essere usati solamente layer *Dense*.\n",
    "- È possibile usare un multiclassificatore, ma solo combinando più reti neurali (e non altri classificatori visti in precedenza come SVM e RandomForest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "Si addestri il modello desiderato utilizzando l'architettura, l'ottimizzatore e i relativi iperparametri trovati nell'esercizio precedente. Il codice contenuto nella cella seguente userà tale modello per predire la classe dei pattern del dataset di test. Le classi predette verranno salvate su un file di testo che dovrà essere caricato sul sito della competizione per misurarne l'accuratezza.\n",
    "Le procedure utilizzate per caricare i dataset e per addestrare la rete desiderata dovranno essere riportate nella cella seguente. Ai fini della competizione si ricorda che nel file .zip dovrà essere inclusa anche una cartella \"Codice\" contenente una copia di questo notebook e degli script Python utilizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caricamento del dataset di training\n",
    "train_dataset = np.load('DBs/AudioDigits_ML21_22/audio_ml2122_train.npy')\n",
    "\n",
    "# Conversione dei dati\n",
    "train_x = train_dataset[:,:-2].astype(np.float32)\n",
    "train_y = train_dataset[:, speaker_column].astype(int)\n",
    "\n",
    "# Caricamento del dataset di test\n",
    "test_dataset = np.load('DBs/AudioDigits_ML21_22/audio_ml2122_test_no_labels.npy')\n",
    "\n",
    "# Conversione dei dati\n",
    "test_x = test_dataset.astype(np.float32)\n",
    "\n",
    "# Scaling dei dati ...\n",
    "\n",
    "# Addestramento del modello\n",
    "# ...\n",
    "\n",
    "predictions = model.predict(test_x)\n",
    "predictions = predictions.argmax(axis=-1)\n",
    "np.savetxt('Es7Predictions.txt', predictions.astype(int), fmt='%i')\n",
    "print('Ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
