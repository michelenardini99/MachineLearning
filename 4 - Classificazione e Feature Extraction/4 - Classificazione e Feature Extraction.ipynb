{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenuti\n",
    "- [Scikit-image](#Scikit-image)\n",
    "- [Import delle librerie](#Import-delle-librerie)\n",
    "- [Caricamento del dataset](#Caricamento-del-dataset)\n",
    "- [Classificazione a partire dai pixel](#Classificazione-a-partire-dai-pixel)\n",
    "- [Estrazione delle feature (HOG)](#Estrazione-delle-feature-%28HOG%29)\n",
    "- [Addestramento del classificatore](#Addestramento-del-classificatore)\n",
    "- [Esercizio](#Esercizio)\n",
    "- [Test](#Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 4\n",
    "Nell'esercitazione odierna si applicheranno diversi algoritmi classici di Machine Learning (*SVM*, *k-NN*, *Random Forest* e *AdaBoost*) a un problema di classificazione binario di **immagini RGB** raffiguranti cani e gatti.\n",
    "\n",
    "Al fine di manipolare e adattare le immagini verranno utilizzate alcune funzionalità messe a disposizione dalla libreria **Scikit-image**. \n",
    "\n",
    "Nel corso dell'esercitazione si dovranno individuare l'algoritmo e le combinazioni di iperparametri che permettono di massimizzare l’accuratezza sul dataset fornito. A tal fine si faccia riferimento alle tecniche viste nell'ambito dell'esercitazione precedente.\n",
    "\n",
    "Infine si dovrà verificare l'accuratezza della soluzione trovata sul dataset di test per provarne l’effettiva capacità di generalizzazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-image\n",
    "Scikit-image è una libreria Python che mette a disposizione numerose classi e funzionalità per l'elaborazione di immagini.\n",
    "\n",
    "Condivide con Scikit-learn la facilità d'uso, l'ampia possibilità di parametrizzare le operazioni messe a disposizione e l'integrazione con la libreria Numpy. Allo stesso modo lo stile della documentazione e della API è estremamente simile a quello di Scikit-learn.\n",
    "\n",
    "Per una lista completa delle funzionalità si rimanda alla [documentazione ufficiale](http://scikit-image.org/docs/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import delle librerie\n",
    "Per prima cosa è necessario eseguire l'import delle librerie utilizzate durante l'esecitazione. Il modulo necessario per utilizzare la libreria Scikit-image si chiama **skimage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Memory\n",
    "from skimage import feature, color, transform\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "\n",
    "import ml_utilities\n",
    "import ml_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricamento del dataset\n",
    "Il dataset consiste in un insieme di immagini RGB di cani e gatti. Prima di caricarlo è necessario definire:\n",
    "- il percorso in cui sono memorizzate le immagini dei dataset (*db_path*);\n",
    "- il percorso di una cartella di lavoro (*exp_path*) dove, durante l'elaborazione, saranno memorizzati file intermedi;\n",
    "- il path del file contenente la lista delle immagini e relative etichette di classe da utilizzare come training set (*train_filelist*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'DBs/CaniGatti_ML18'\n",
    "exp_path = 'Experiments'\n",
    "train_filelist = 'BinaryTrainingSet.txt'  \n",
    "\n",
    "# Predisposizione di un'area di caching su disco che velocizza la riesecuzione di chiamate di funzioni con gli stessi parametri\n",
    "memory = Memory(exp_path, verbose=0)  \n",
    "\n",
    "# Caricamento delle immagini\n",
    "print('Caricamento in corso ...')\n",
    "start = time.time()\n",
    "train_raw_x, train_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
    "\n",
    "print('Caricate %d immagini in %.2f s.' % (len(train_raw_x), time.time() - start))\n",
    "print('Gatti:', np.count_nonzero(train_y == 0))\n",
    "print('Cani:', np.count_nonzero(train_y == 1))\n",
    "\n",
    "# Shuffle del training set\n",
    "ml_utilities.shuffle_in_unison([train_raw_x, train_y], seed=1234)\n",
    "\n",
    "# Visualizzazione immagini\n",
    "_, axs = plt.subplots(2, 5,figsize=(30, 15))\n",
    "for i in range(5):\n",
    "    axs[0,i].imshow(train_raw_x[i]),axs[0,i].axis('off')\n",
    "    axs[1,i].imshow(train_raw_x[5+i]),axs[1,i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se le dimensioni delle immagini in input sono eterogenee, prima di poterle utilizzare è necessario portarle tutte a delle dimensioni prefissate ($\\textit{image_side} \\times \\textit{image_side}$) come mostrato nella cella seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizing = True\n",
    "image_side = 128\n",
    "\n",
    "if resizing:\n",
    "    # Resize\n",
    "    print('Resizing in corso ...')\n",
    "    start = time.time()\n",
    "    train_raw_x = ml_utilities.resize_images(train_raw_x, image_side, image_side, cache=memory)\n",
    "    \n",
    "    print('Resizing completato in %.2f s.' % (time.time() - start))\n",
    "    \n",
    "    # Visualizzazione immagini\n",
    "    _, axs = plt.subplots(2, 5,figsize=(30, 15))\n",
    "    for i in range(5):\n",
    "        axs[0,i].imshow(train_raw_x[i]),axs[0,i].axis('off')\n",
    "        axs[1,i].imshow(train_raw_x[5+i]),axs[1,i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione a partire dai pixel\n",
    "\n",
    "Le immagini ottenute (anche a seguito di *resizing*) sono molto grandi per poter essere utilizzate direttamente come input di un classificatore tradizionale. Infatti un'immagine $\\textit{128} \\times \\textit{128} \\times \\textit{3}$ corrisponde a un pattern 49152-dimensionale.\n",
    "\n",
    "Utilizzando un *SVM* il tempo di training è di circa 2 minuti (utilizzando la classe **LinearSVC** ottimizzata per *kernel* lineare) per ottenere un'accuratezza intorno al 57% (di poco superiore alla scelta casuale!).\n",
    "\n",
    "Nel settore della visione artificiale per l'addestramento di classificatori (qualora non si utilizzino tecniche di deep learning quali le reti CNN) è prassi consolidata estrarre dalle immagini feature **robuste** e **compatte**.\n",
    "\n",
    "Perchè l'intensità dei pixel non è una feature robusta?\n",
    "<img src=\"pixel_dist.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Variazioni di posa, e illuminazione possono rendere campioni della stessa classe molto diversi tra loro in termini di intensità di pixel corrispondenti.\n",
    "\n",
    "Purtroppo non esiste un tipo di feature idoneo per tutti i problemi ma è necessario padroneggiare il dominio applicativo per scegliere/progettare in modo ottimale le feature da utilizzare (si parla di *feature engineering* o *handcrafted features*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrazione delle feature (HOG)\n",
    "In questa esercitazione utilizzeremo le feature note come *Histogram of Oriented Gradients* ([HOG](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients)), originariamente introdotte per *pedestrian detection*, ma applicabili anche ad altri domini.\n",
    "\n",
    "Un'implementazione è disponibile nella libreria  [Scikit-image](http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog).\n",
    "\n",
    "Per estrarre le orientazioni, il metodo HOG non ha evidenti vantaggi dall'uso del colore. Pertanto prima dell'estrazione le immagini possono essere convertite da RGB (3 byte per pixel) in scala di grigi (1 byte per pixel).\n",
    "\n",
    "L'immagine viene suddivida in blocchi. Per ognuno di essi HOG estrae le orientazioni del gradiente e le riassume attraverso un istogramma. \n",
    "\n",
    "La funzione **hog(...)** restituisce un **ndarray** monodimensionale contenente le feature estratte. Con il paramentro opzionale (*visualise*) è possibile ottenerne una visualizzazione grafica utile per comprendere meglio la natura delle feature estratte. La cella seguente visualizza una rappresentazione HOG relativa a un'immagine di esempio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 1  # Modificare con un indice a piacere\n",
    "\n",
    "# Conversione in grayscale\n",
    "grayscale_image = color.rgb2gray(train_raw_x[image_index])  \n",
    "\n",
    "# Estrazione delle feature\n",
    "hog_features, hog_image = feature.hog(grayscale_image,\n",
    "                                      orientations=9, pixels_per_cell=(8, 8),\n",
    "                                      cells_per_block=(1, 1),  block_norm='L2-Hys',\n",
    "                                      visualize=True)  \n",
    "\n",
    "print('Numero feature:', len(hog_features))\n",
    "\n",
    "# Visualizzazione HOG\n",
    "_, axs = plt.subplots(1, 2,figsize=(12, 6))\n",
    "axs[0].imshow(train_raw_x[image_index]),axs[0].axis('off')\n",
    "axs[1].imshow(hog_image),axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procedura appena descritta deve essere applicata a tutte le immagini. Per fare ciò è possibile utilizzare la funzione **extract_hog(...)** del modulo *ml_utilities* come mostrato di seguito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estrazione delle feature HOG in corso ...')\n",
    "start = time.time()\n",
    "train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=9,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "print('Estrazione completata in %.2f s.' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento del classificatore\n",
    "Completata la fase di **estrazione** delle feature, è possibile utilizzarle per addestrare un classificatore.\n",
    "\n",
    "Il dataset *train_feature_x* e la lista delle etichette di classe *train_y* sono nel formato richiesto dall'API di Scikit-learn.\n",
    "\n",
    "In Scikit-learn oltre a [*k-NN*](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) e [*SVM*](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (visti nell'esercitazione precedente) sono presenti anche i classificatori [*Random Forest*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [*AdaBoost*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). \n",
    "\n",
    "Di seguito vengono riportate le istruzioni necessarie per creare e addestrare un classificatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf = KNeighborsClassifier()\n",
    "#clf = SVC()\n",
    "#clf = RandomForestClassifier(random_state=1234)\n",
    "#clf = AdaBoostClassifier(random_state=1234)\n",
    "\n",
    "print('Addestramento in corso ...')\n",
    "clf.fit(train_feature_x, train_y)\n",
    "print('Addestramento completato in %.2f s.' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È possibile stimare l'accuratezza di un classificatore utilizzando il metodo **.predict(...)**. Il metodo restituisce le predizioni del classificatore su un insieme di pattern che, confrontate con le etichette reali, permettono di calcolarne l'accuratezza. Ad esempio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valutazione sul training set in corso ...')\n",
    "start = time.time()\n",
    "train_predictions = clf.predict(train_feature_x)\n",
    "print('Valutazione sul training set completata in %.2f s.' % (time.time() - start))\n",
    "\n",
    "# Calcolo accuratezza\n",
    "train_accuracy = (train_predictions == train_y).sum()/len(train_y)\n",
    "print('Accuratezza:', train_accuracy)\n",
    "\n",
    "# Visualizzazione Confusion Matrix\n",
    "ml_visualization.plot_confusion_matrix(train_y, train_predictions, ['Cat', 'Dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Esercizio\n",
    "L'obiettivo è massimizzare l'accuratezza di classificazione, valutando (con *Cross-Validation*):\n",
    "- l'impiego di diversi classificatori, come [*k-NN*](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [*SVM*](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), [*Random Forest*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [*AdaBoost*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) o altri. È possibile utilizzare qualsiasi tipologia di classificatore tranne quelli basati su reti neurali.\n",
    "- l'ottimizzazione dei relativi iperparametri;\n",
    "- l'ottimizzazione dei parametri utilizzati per estrarre le feature HOG;\n",
    "- la combinazione di più classificatori.\n",
    "\n",
    "Si consiglia di procedere iterativamente a partire da un insieme limitato di combinazioni per poi raffinare la ricerca: infatti, i tempi richiesti per l'esecuzione di [**cross_val_score(...)**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) e [**GridSearchCV(...)**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) possono diventare proibitivi per un elevato numero di combinazioni di iperparametri e *fold*.\n",
    "\n",
    "**NOTA BENE:**\n",
    " - Il classificatore dovrà essere **addestrato e testato sulle feature HOG** estratte dai pattern del dataset (quindi non direttamente sulle immagini originali);\n",
    " - Non è (ovviamente) possibile utilizzare i pattern del test set per l'addestramento del classificatore;\n",
    " - **Non è consentito aggiungere immagini esterne** al training set così come non è possibile utilizzare immagini derivate (*augmentation*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 1: ottimizzazione iperparametri\n",
    "\n",
    "# La strategia migliore è quella di utilizzare GridSearchCV sull'intero dataset\n",
    "# tentando diverse combinazioni di iperparametri.\n",
    "# Di seguito è riportato il codice visto durante la scorsa esercitazione\n",
    "# in una versione adattata per utilizzare anche Random Forest e AdaBoost.\n",
    "\n",
    "# Creazione del classificatore e della griglia di iperparametri\n",
    "clf = KNeighborsClassifier()\n",
    "param_grid = [{'n_neighbors': range(3, 7)}]\n",
    "\n",
    "#clf = SVC()\n",
    "#param_grid = [{'kernel': ['linear'], 'C': [1, 5, 10]}]\n",
    "\n",
    "#clf = SVC()\n",
    "#param_grid = [{'kernel': ['rbf'], 'C': [1, 5], 'gamma': [1.0, 0.5]}]\n",
    "\n",
    "#clf = RandomForestClassifier(random_state=1234)\n",
    "#param_grid = [{'n_estimators': [10, 50, 100], 'max_depth': [None, 2, 3]}]\n",
    "\n",
    "#clf = AdaBoostClassifier(random_state=1234)\n",
    "#param_grid = [{'n_estimators': [50], 'learning_rate': [0.75, 1.0]}]\n",
    "\n",
    "\n",
    "# Numero di fold per la Cross-validation\n",
    "n_folds = 3\n",
    "\n",
    "# Creazione di un oggetto di tipo GridSearchCV\n",
    "experiment_gscv = GridSearchCV(clf, param_grid, cv=n_folds)\n",
    "\n",
    "# Esecuzione della ricerca degli iperparametri \n",
    "experiment_gscv.fit(train_feature_x, train_y)\n",
    "\n",
    "# Stampa risultati\n",
    "print('Combinazioni di parametri:\\n', experiment_gscv.cv_results_['params'])\n",
    "print('Accuratezza media per combinazione:\\n', experiment_gscv.cv_results_['mean_test_score'])\n",
    "print('Combinazione migliore:\\n', experiment_gscv.best_params_)\n",
    "print('Accuratezza media della combinazione migliore: %.3f' % experiment_gscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "Si addestri il classificatore desiderato utilizzando gli iperparametri trovati nell'esercizio precedente. Il codice contenuto nella cella seguente userà tale classificatore per predire la classe dei pattern del dataset di test. Le classi predette verranno salvate su un file di testo che dovrà essere caricato sul sito della competizione per misurarne l'accuratezza.\n",
    "Le procedure utilizzate per caricare i dataset, per estrarne le feature e per addestrare il classificatore desiderato dovranno essere riportate nella cella seguente. Ai fini della competizione si ricorda che nel file .zip dovrà essere inclusa anche una cartella \"Codice\" contenente una copia di questo notebook e degli script Python utilizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Esercizio 2: valutazione su test set\n",
    "\n",
    "# Soluzione:\n",
    "# sono forniti i migliori parametri trovati da GridSearchCV utilizzando\n",
    "# le combinazioni riportate nel codice della cella precedente (sezione 'Esercizio').\n",
    "# È possibile fare di meglio?\n",
    "\n",
    "# Path contenente i pattern di test\n",
    "image_side = 128\n",
    "db_path = 'DBs/CaniGatti_ML18'\n",
    "exp_path = 'Experiments'\n",
    "train_filelist = 'BinaryTrainingSet.txt' \n",
    "test_filelist = 'Unlabeled_BinaryTestSet.txt'\n",
    "result_path = 'Es4Predictions.txt'\n",
    "memory = Memory(exp_path, verbose=0) \n",
    "\n",
    "# Caricamento dei pattern di training\n",
    "train_raw_x, train_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
    "\n",
    "# Preprocessing ed estrazione HOG (training)\n",
    "train_raw_x = ml_utilities.resize_images(train_raw_x, image_side, image_side, cache=memory)\n",
    "train_feature_x = ml_utilities.extract_hog(train_raw_x, \n",
    "                                           convert_to_gray=True, orientations=9,\n",
    "                                           pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                           cache=memory)\n",
    "\n",
    "# Creazione del classificatore\n",
    "start = time.time()\n",
    "clf = KNeighborsClassifier(n_neighbors=4)                                          # Accuracy: 62.0%\n",
    "#clf = SVC(kernel='linear', C=1)                                                    # Accuracy: 63.3%\n",
    "#clf = SVC(kernel='rbf', C=1, gamma=1.0)                                            # Accuracy: 56.7%\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=1234)  # Accuracy: 76.0%\n",
    "#clf = AdaBoostClassifier(learning_rate=1.0, n_estimators=50, random_state=1234)    # Accuracy: 73.3%\n",
    "\n",
    "# Addestramento del classificatore\n",
    "print('Addestramento in corso ...')\n",
    "clf.fit(train_feature_x, train_y)\n",
    "print('Addestramento completato in %.2f s.' % (time.time() - start))\n",
    "\n",
    "# Caricamento dei pattern di test\n",
    "test_raw_x = ml_utilities.load_unlabeled_dataset(test_filelist, db_path, cache=memory)\n",
    "\n",
    "# Preprocessing ed estrazione HOG (test)\n",
    "test_raw_x = ml_utilities.resize_images(test_raw_x, image_side, image_side, cache=memory)\n",
    "test_feature_x = ml_utilities.extract_hog(test_raw_x, \n",
    "                                          convert_to_gray=True, orientations=9,\n",
    "                                          pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n",
    "                                          cache=memory)\n",
    "\n",
    "# Salvataggio delle predictions\n",
    "predictions = clf.predict(test_feature_x)\n",
    "\n",
    "with open(result_path, \"w\") as f:\n",
    "    for prediction in predictions:\n",
    "        f.write(str(int(prediction)) + '\\n')\n",
    "print('Ok')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
